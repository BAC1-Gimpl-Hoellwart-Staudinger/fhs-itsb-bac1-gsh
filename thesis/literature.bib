@legislation{_CouncilDirective89_1989,
  title = {Council {{Directive}} 89/391/{{EEC}} of 12 {{June}} 1989 on the Introduction of Measures to Encourage Improvements in the Safety and Health of Workers at Work},
  date = {1989-06-29},
  journaltitle = {183},
  volume = {OJ L},
  url = {http://data.europa.eu/eli/dir/1989/391/oj/eng},
  urldate = {2021-04-14},
  langid = {english},
  number = {31989L0391}
}

@online{_DINISO924111_,
  title = {DIN EN ISO 9241-11},
  shorttitle = {DIN EN ISO 9241-11},
  url = {https://www.din.de/de/mitwirken/normenausschuesse/naerg/veroeffentlichungen/wdc-beuth:din21:279590417},
  urldate = {2021-04-14},
  file = {/home/valentin/Zotero/storage/W5C4A3F4/wdc-beuthdin21279590417.html},
  langid = {german},
  organization = {{Ergonomie der Mensch-System-Interaktion - Teil 11: Gebrauchstauglichkeit: Begriffe und Konzepte (ISO 9241-11:2018); Deutsche Fassung EN ISO 9241-11:2018}}
}

@report{_DINISO9241110_,
  title = {{{DIN EN ISO}} 9241-110:2020-10, {{Ergonomie}} Der {{Mensch}}-{{System}}-{{Interaktion}} - {{Teil}} 110: {{Interaktionsprinzipien}} ({{ISO}} 9241-110:2020); {{Deutsche Fassung EN ISO}} 9241-110:2020},
  shorttitle = {{{DIN EN ISO}} 9241-110},
  institution = {{Beuth Verlag GmbH}},
  doi = {10.31030/3147467}
}

@report{_DINISO9241110_a,
  title = {{{DIN EN ISO}} 9241-110:2008-09, {{Ergonomie}} Der {{Mensch}}-{{System}}-{{Interaktion}} - {{Teil}} 110: {{Grunds\"atze}} Der {{Dialoggestaltung}} ({{ISO}} 9241-110:2006); {{Deutsche Fassung EN ISO}} 9241-110:2006},
  shorttitle = {{{DIN EN ISO}} 9241-110},
  institution = {{Beuth Verlag GmbH}},
  doi = {10.31030/1464024}
}

@online{_DINISO9241110_b,
  title = {{{DIN EN ISO}} 9241-110 - 2020-10 - {{Beuth}}.De},
  url = {https://www.beuth.de/de/norm/din-en-iso-9241-110/320862700},
  urldate = {2021-05-06},
  file = {/home/valentin/Zotero/storage/AU4VAKGV/320862700.html}
}

@inreference{_ISO9241_2020,
  title = {ISO 9241},
  booktitle = {Wikipedia},
  date = {2020-11-08T18:51:26Z},
  url = {https://de.wikipedia.org/w/index.php?title=ISO_9241&oldid=205330133},
  urldate = {2021-02-26},
  abstract = {Die Norm ISO 9241 ist ein internationaler Standard, der Richtlinien der Mensch-Computer-Interaktion beschreibt. Die Normenreihe tr\"agt seit 2006 den deutschen Titel Ergonomie der Mensch-System-Interaktion und l\"ost damit den bisherigen Titel Ergonomische Anforderungen f\"ur B\"urot\"atigkeiten mit Bildschirmger\"aten ab, um die fr\"uhere Einschr\"ankung auf B\"uroarbeit aufzul\"osen. Die Normenreihe beschreibt Anforderungen an die Arbeitsumgebung, Hardware und Software. Ziel der Richtlinie ist es, gesundheitliche Sch\"aden beim Arbeiten am Bildschirm zu vermeiden und dem Benutzer die Ausf\"uhrung seiner Aufgaben zu erleichtern. Auf der Grundlage einer Norm der internationalen Normungsorganisation ISO wurde eine Europ\"aische Norm erarbeitet, die EN ISO 9241, die in Deutschland als DIN-Norm DIN EN ISO 9241 \"ubernommen wurde, in \"Osterreich existiert die inhaltlich identische \"ONORM EN ISO 9241. Die EN ISO 9241 gilt nach EU-Rechtsprechung auch als Standard zur Bewertung der Forderung nach Benutzerfreundlichkeit, in Deutschland aus der Arbeitsst\"attenverordnung (ArbSt\"attV), bis zum 3. Dezember  2016 Bildschirmarbeitsverordnung (BildscharbV).},
  annotation = {Page Version ID: 205330133},
  file = {/home/valentin/Zotero/storage/PJ4N8WJK/index.html},
  langid = {german}
}

@online{_PerformanceWhatConsidered_,
  title = {Performance - {{What}} Is Considered a Good Response Time for a Dynamic, Personalized Web Application?},
  url = {https://stackoverflow.com/questions/164175/what-is-considered-a-good-response-time-for-a-dynamic-personalized-web-applicat},
  urldate = {2021-05-17},
  file = {/home/valentin/Zotero/storage/957NUEDP/what-is-considered-a-good-response-time-for-a-dynamic-personalized-web-applicat.html},
  organization = {{Stack Overflow}}
}

@online{_TLXNASAAmes_,
  title = {{{TLX}} @ {{NASA Ames}} - {{Home}}},
  url = {https://humansystems.arc.nasa.gov/groups/TLX/},
  urldate = {2021-05-12},
  file = {/home/valentin/Zotero/storage/NCJILD4T/TLX.html}
}

@online{_TopologyAnalysisLearning_,
  title = {Topology {{Analysis}} of {{Learning Cognitive Flow}} for {{Human}}-{{Computer Interaction}}},
  url = {http://ieeexplore.ieee.org/document/8589388/},
  urldate = {2021-05-05},
  abstract = {In recent years, improving the level of personalized education has attracted research interest of a great amount of people. However, it is difficult to make the high dimensional cognitive learning space visible, computational and controllable. Whats more, manual data collection is difficult to meet the quantity and accuracy requirements, bringing obstacles in observing more accurate learning activities and collect more effective information. In this paper, a cognitive frame for observing the learning activities based on human-computer coupling is designed, for instance a vectorization technique for the situation of learning of human-computer is provided. Firstly, based on new cognitive philosophy such as cognitive distribution and extension, we propose a general topology of learning cognitive flow for human-computer interaction, composing of an evolving and high-dimensional system. The cognitive objects and their relationships are in an implicit learning, namely, cognitive space is in a human-computer coupling state.Those are distributed and extended to an information space, so as to form a ``brain cognitive body-situation of coupling-manifold of information'', which is a combination of cognition and information, named ``BSM'' structure. Furthermore, the mechanism for the BSM coupling morphism is analyzed, and the principle for the coupled observation of objects in a cognitive or learning manifold is proposed. At the same time, based on the concepts of category theory, such as commutative diagram and topology, a tree topology is selected as the topological structure of a low-dimensional learning space to process the observations of online learning. Finally, a special system for teaching is programmed to observe learning and training processes, thus summarizing knowledge points automatically to replace the manual way. The application of system will enable the teacher to better grasp students status of cognitive structure obviously, providing services to teaching. A new application framework for learning and a new idea for the scientific studies on learning are provided, supporting for``artificial education'' to ``human-computer learning'' effectively.},
  langid = {american}
}

@online{_UsGNOME_,
  title = {About {{Us}} \textendash{} {{GNOME}}},
  url = {https://www.gnome.org/about-us/},
  urldate = {2021-05-25},
  file = {/home/valentin/Zotero/storage/4TGUXKJW/about-us.html},
  langid = {american}
}

@inproceedings{adewumi_EvaluatingOpenSource_2015,
  title = {Evaluating {{Open Source Software Quality Models Against ISO}} 25010},
  booktitle = {2015 {{IEEE International Conference}} on {{Computer}} and {{Information Technology}}; {{Ubiquitous Computing}} and {{Communications}}; {{Dependable}}, {{Autonomic}} and {{Secure Computing}}; {{Pervasive Intelligence}} and {{Computing}}},
  author = {Adewumi, A. and Misra, S. and Omoregbe, N.},
  date = {2015-10},
  pages = {872--877},
  doi = {10.1109/CIT/IUCC/DASC/PICOM.2015.130},
  abstract = {Quite a number of open source software quality models exist today. These models emerged as a result of the need to measure quality in open source software, which is quite unlike closed source, or proprietary software. ISO 9126 standard forms the basis from which most of these models derive. However, ISO 9126 standard has been replaced by ISO 25010. Therefore, as research endeavors progress towards evolving the "silver bullet" open source software quality model, it is the aim of this paper to evaluate existing open source software quality models against the ISO 25010 standard. The findings from this study reveal a candidate model (from among the existing models) that can be leveraged in deriving a generic open source software quality model.},
  eventtitle = {2015 {{IEEE International Conference}} on {{Computer}} and {{Information Technology}}; {{Ubiquitous Computing}} and {{Communications}}; {{Dependable}}, {{Autonomic}} and {{Secure Computing}}; {{Pervasive Intelligence}} and {{Computing}}},
  file = {/home/valentin/Zotero/storage/TA8957F3/Adewumi et al. - 2015 - Evaluating Open Source Software Quality Models Aga.pdf;/home/valentin/Zotero/storage/5PDAN598/7363170.html},
  keywords = {Adaptation models,evaluation,ISO 25010,ISO 9126,ISO Standards,open source software,Open source software,quality models,Security,Usability}
}

@inproceedings{basri_ConceptualizingUnderstandingUser_2016,
  title = {Conceptualizing and Understanding User Experience},
  booktitle = {2016 4th {{International Conference}} on {{User Science}} and {{Engineering}} (i-{{USEr}})},
  author = {Basri, Nasrah Hassan and Noor, Nor Laila Md. and Adnan, Wan Adilah Wan and Saman, Fauzi Mohd. and Baharin, Ahmad Hanif Ahmad},
  date = {2016-08},
  pages = {81--84},
  doi = {10.1109/IUSER.2016.7857938},
  abstract = {Over the years, User Experience (UX) becomes a main term in designing an interactive product. The term itself lacks proper theoretical definition and is used in many different ways especially in academic and industry. This paper reviews and explores various existing approaches to conceptualize and understand user experience better. It covers both theories from the academics as well as studies conducted by the industries. Industries seem to treat user experience as a conventional usability while academics are more dynamic in defining user experience. Thus, this paper is trying to provide a base in conceptualizing and understanding user experience by covering different topics related to user experience.},
  eventtitle = {2016 4th {{International Conference}} on {{User Science}} and {{Engineering}} (i-{{USEr}})},
  file = {/home/valentin/Zotero/storage/3FCWTXQD/Basri et al. - 2016 - Conceptualizing and understanding user experience.pdf;/home/valentin/Zotero/storage/JQ52F7CS/7857938.html},
  keywords = {Conferences,Context,dynamic,hedonic,Human factors,Industries,Interactive systems,pragmatic,Pragmatics,Usability,user experience}
}

@article{bastien_UsabilityTestingReview_2009,
  title = {Usability Testing: {{A}} Review of Some Methodological and Technical Aspects of the Method},
  shorttitle = {Usability Testing},
  author = {Bastien, J.},
  date = {2009-05-01},
  journaltitle = {International journal of medical informatics},
  shortjournal = {International journal of medical informatics},
  volume = {79},
  pages = {e18-23},
  doi = {10.1016/j.ijmedinf.2008.12.004},
  abstract = {The aim of this paper is to review some work conducted in the field of user testing that aims at specifying or clarifying the test procedures and at defining and developing tools to help conduct user tests. The topics that have been selected were considered relevant for evaluating applications in the field of medical and health care informatics. These topics are: the number of participants that should take part in a user test, the test procedure, remote usability evaluation, usability testing tools, and evaluating mobile applications.},
  file = {/home/valentin/Zotero/storage/P2QDLPR2/Bastien - 2009 - Usability testing A review of some methodological.pdf}
}

@inproceedings{bevan_MagicNumberIt_2003,
  title = {The "Magic Number 5": Is It Enough for Web Testing?},
  shorttitle = {The "Magic Number 5"},
  author = {Bevan, Nigel and {Nigel} and Barnum, Carol and {Carol} and Cockton, Gilbert and {Gilbert} and {Nielsen} and {Jakob} and Spool, Jared and {Jared} and Wixon, Dennis and {Dennis}},
  date = {2003-04-05},
  doi = {10.1145/765891.765936},
  abstract = {Common practice holds that 80\% of usability findings are discovered after five participants. Recent findings from web testing indicate that a much larger number of participants is required to get results and that independent teams testing the same web-based product do not replicate results. How many users are enough for web testing?},
  file = {/home/valentin/Zotero/storage/63YVU5EL/Bevan et al. - 2003 - The magic number 5 is it enough for web testing.pdf}
}

@article{bevan_MeasuringUsabilityQuality_1995,
  title = {Measuring Usability as Quality of Use},
  author = {Bevan, Nigel},
  date = {1995-06},
  journaltitle = {Software Quality Journal},
  shortjournal = {Software Qual J},
  volume = {4},
  pages = {115--130},
  doi = {10.1007/BF00402715},
  langid = {english},
  number = {2}
}

@misc{caldwel_WebContentAccessibility_2008,
  title = {Web {{Content Accessibility Guidelines}} ({{WCAG}}) 2.0},
  shorttitle = {{{WCAG20}}},
  author = {Caldwel, Ben and Cooper, Michael and Guarino Reid, Loretta and Vanderheiden, Gregg},
  date = {2008-12-11},
  publisher = {{World Wide Web Consortium}},
  url = {https://www.w3.org/TR/2008/REC-WCAG20-20081211/},
  urldate = {2021-04-16},
  file = {/home/valentin/Zotero/storage/L82A2CBT/Caldwel et al. - 2008 - Web Content Accessibility Guidelines (WCAG) 2.0.pdf;/home/valentin/Zotero/storage/A5ZMTII3/REC-WCAG20-20081211.html}
}

@inproceedings{card_InformationVisualizerInformation_1991,
  title = {The {{Information Visualizer}}, an {{Information Workspace}}},
  author = {Card, Stuart and Robertson, George and Mackinlay, Jock},
  date = {1991-01-01},
  pages = {181--186},
  doi = {10.1145/108844.108874},
  abstract = {This paper proposes a concept for the user interface of information retrieval systems called an information workspace. The concept goes beyond the usual notion of an information retrieval system to encompass the cost structure of information from secondary storage to immediate use. As an implementation of the concept, the paper describes an experimental system, called the Information Visualizer, and its rationale. The system is based on (1) the use of 3D/Rooms for increasing the capacity of immediate storage avaitable to the user, (2) the Cognitive Co-processor scheduler-based user interface interaction architecture for coupling the user to information agents, and (3) the use of information visualization for interacting with information structure.},
  eventtitle = {Proceedings of {{CHI}}'91},
  file = {/home/valentin/Zotero/storage/7FFSMTD9/Card et al. - 1991 - The Information Visualizer, an Information Workspa.pdf}
}

@book{card_PsychologyHumanComputerInteraction_1986,
  title = {The Psychology of Human-Computer Interaction},
  author = {Card, Stuart K. and Moran, Thomas P. and Newell, Allen},
  date = {1986-02-01},
  edition = {1. Edition},
  publisher = {{Lawrence Erlbaum Associates}},
  location = {{Boca Raton, Fla. London New York}},
  file = {/home/valentin/Zotero/storage/4WUVPPAZ/Card et al. - 1986 - The Psychology of Human-Computer Interaction.pdf},
  langid = {Englisch}
}

@article{constantinescu_UsabilityTestingMHealth_2019,
  title = {Usability Testing of an {{mHealth}} Device for Swallowing Therapy in Head and Neck Cancer Survivors},
  author = {Constantinescu, Gabriela and Kuffel, Kristina and King, Ben and Hodgetts, William and Rieger, Jana},
  date = {2019-12-01},
  journaltitle = {Health Informatics Journal},
  shortjournal = {Health Informatics J},
  volume = {25},
  pages = {1373--1382},
  publisher = {{SAGE Publications Ltd}},
  doi = {10.1177/1460458218766574},
  abstract = {The objective of this study was to conduct the first patient usability testing of a mobile health (mHealth) system for in-home swallowing therapy. Five participants with a history of head and neck cancer evaluated the mHealth system. After completing an in-application (app) tutorial with the clinician, participants were asked to independently complete five tasks: pair the device to the smartphone, place the device correctly, exercise, interpret progress displays, and close the system. Quantitative and qualitative methods were used to evaluate the effectiveness, efficiency, and satisfaction with the system. Critical changes to the app were found in three of the tasks, resulting in recommendations for the next iteration. These issues were related to ease of Bluetooth pairing, placement of device, and interpretation of statistics. Usability testing with patients identified issues that were essential to address prior to implementing the mHealth system in subsequent clinical trials. Of the usability methods used, video observation (synced screen capture with videoed gestures) revealed the most information.},
  file = {/home/valentin/Zotero/storage/EXAB863C/Constantinescu et al. - 2019 - Usability testing of an mHealth device for swallow.pdf},
  keywords = {deglutition disorders,head and neck cancer,mHealth,mobile apps,usability},
  langid = {english},
  number = {4}
}

@book{dix_HumancomputerInteraction_2004,
  title = {Human-Computer Interaction},
  editor = {Dix, Alan},
  date = {2004},
  edition = {3rd ed},
  publisher = {{Pearson/Prentice-Hall}},
  location = {{Harlow, England ; New York}},
  file = {/home/valentin/Zotero/storage/56H72YX9/Dix - 2004 - Human-computer interaction.pdf},
  keywords = {Human-computer interaction},
  langid = {english}
}

@inproceedings{dordevic_SoftwareToolEvaluation_2007,
  title = {Software {{Tool}} for {{Evaluation}} of {{Human Cognitive Characteristics}} in {{Interaction}} with {{Computer}}},
  booktitle = {2007 8th {{International Conference}} on {{Telecommunications}} in {{Modern Satellite}}, {{Cable}} and {{Broadcasting Services}}},
  author = {Dordevic, Nebojsa D. and Rancic, Dejan D.},
  date = {2007-09},
  pages = {446--449},
  doi = {10.1109/℡SKS.2007.4376035},
  abstract = {This paper presents an extension of cognitive model for Human-Computer Interaction (HCI) - XUAN/t, based on decomposition of user dialogue into elementary actions (GOMS). Using this model, descriptions of elementary actions performed by user and system are introduced sequentially, as they will happen. Based on the described model and psychometric concepts, we developed software tool for testing sensomotor abilities of users for HCI. Software tool arranges tests into test groups for psychosensomotor and memory capabilities. User test results are stored in a database and available for further statistical analysis.},
  eventtitle = {2007 8th {{International Conference}} on {{Telecommunications}} in {{Modern Satellite}}, {{Cable}} and {{Broadcasting Services}}},
  file = {/home/valentin/Zotero/storage/GDS8EWKH/Dordevic and Rancic - 2007 - Software Tool for Evaluation of Human Cognitive Ch.pdf;/home/valentin/Zotero/storage/6YR8M9LU/4376035.html},
  keywords = {Application software,Databases,HCI,Human computer interaction,Psychology,Psychometric testing,Software Evaluation,Software testing,Software tools,Software Usability,Statistical analysis,Usability,User interface,User interfaces}
}

@online{duncan_ISO92411102020_,
  title = {{{ISO}} 9241-110:2020},
  shorttitle = {{{ISO}} 9241-110},
  author = {Duncan, Jacky and Earthy, Jonathan and Garcia, Blandine and Reid, David},
  url = {https://www.iso.org/cms/render/live/en/sites/isoorg/contents/data/standard/07/52/75258.html},
  urldate = {2021-02-28},
  abstract = {Ergonomics of human-system interaction \textemdash{} Part 110: Interaction principles},
  file = {/home/valentin/Zotero/storage/DUED8B4H/75258.html},
  langid = {english},
  organization = {{ISO}}
}

@online{farrell_UXResearchCheat_2017,
  title = {{{UX Research Cheat Sheet}}},
  author = {Farrell, Susan},
  date = {2017-02-12},
  url = {https://www.nngroup.com/articles/ux-research-cheat-sheet/},
  urldate = {2021-04-14},
  abstract = {User research can be done at any point in the design cycle. This list of methods and activities can help you decide which to use when.},
  file = {/home/valentin/Zotero/storage/FX3YAL8E/ux-research-cheat-sheet.html},
  langid = {english},
  organization = {{Nielsen Norman Group}}
}

@inproceedings{fetaji_ComparativeStudyEfficiency_2011,
  title = {Comparative Study of Efficiency among the Developed {{MLUAT}} Methodology in Comparison with {{Qualitative User Testing Method}} and {{Heuristics Evaluation}}},
  booktitle = {Proceedings of the {{ITI}} 2011, 33rd {{International Conference}} on {{Information Technology Interfaces}}},
  author = {Fetaji, B. and Fetaji, M. and Kaneko, K.},
  date = {2011-06},
  pages = {269--274},
  abstract = {Mobile learning has been investigated from a range of perspectives, but there is little published research on usability of m-learning environments. To have successful educational m-learning it is essential to devise and implement appropriate usability testing methodologies to evaluate the usability of mobile applications. The research study contribution is the new proposed MLUAT methodology that is been shown more effective in comparison with two other existing usability methods. Additionally the research contribution is comparing the results between two usability testing methods aimed for e-learning and applied in m-learning and the one proposed by the authors called MLUAT usability testing methodology for m-learning and analyzing its efficiency. In appendix are provided the questionnaire and the table of results were the MLUAT methodology shows better results in detecting usability issues then the two existing methodologies.},
  eventtitle = {Proceedings of the {{ITI}} 2011, 33rd {{International Conference}} on {{Information Technology Interfaces}}},
  file = {/home/valentin/Zotero/storage/G5HWETI8/Fetaji et al. - 2011 - Comparative study of efficiency among the develope.pdf;/home/valentin/Zotero/storage/KN95Z2XR/5974034.html},
  keywords = {Conferences,e-learning,Guidelines,Helium,learners environment,m-learning,Mobile communication,mobile devices,Testing,usability,Usability}
}

@inproceedings{fetaji_UniversitiesGoMobile_2008,
  title = {Universities Go Mobile \textemdash{} {{Case}} Study Experiment in Using Mobile Devices},
  booktitle = {{{ITI}} 2008 - 30th {{International Conference}} on {{Information Technology Interfaces}}},
  author = {Fetaji, M. and Fetaji, B.},
  date = {2008-06},
  pages = {123--128},
  doi = {10.1109/ITI.2008.4588394},
  abstract = {The objective of this research was to investigate the possibilities of using mobile applications and mobile devices in university environment. The research integrates several existing technology adoption models and then for the needs of the research conducted and develop a case study experiment. The objective was to raise the communication level and accessibility, as well as the dissemination of knowledge and learning. The significance of the research is based in the fact that today, almost every student has a mobile device at all times while not everyone has a computer and Internet connection at all times. In order to investigate this, a case study experiment was devised. It involved investigation into the factors that influence mobile applications.},
  eventtitle = {{{ITI}} 2008 - 30th {{International Conference}} on {{Information Technology Interfaces}}},
  file = {/home/valentin/Zotero/storage/DNI4ANGG/Fetaji and Fetaji - 2008 - Universities go mobile — Case study experiment in .pdf;/home/valentin/Zotero/storage/FC6TENBD/4588394.html},
  keywords = {Computers,Electronic learning,human-computer interface,Mobile application,Mobile communication,Mobile handsets,Software,usability,Usability,Wireless communication,wireless devices}
}

@inproceedings{fetaji_UsabilityTestingEvaluation_2008,
  title = {Usability Testing and Evaluation of a Mobile Software Solution: {{A}} Case Study},
  shorttitle = {Usability Testing and Evaluation of a Mobile Software Solution},
  booktitle = {{{ITI}} 2008 - 30th {{International Conference}} on {{Information Technology Interfaces}}},
  author = {Fetaji, M. and Dika, Z. and Fetaji, B.},
  date = {2008-06},
  pages = {501--506},
  doi = {10.1109/ITI.2008.4588461},
  abstract = {Learning through mobile devices such as PDAs, mobile phones, laptops with wireless capabilities, today is integrated within education systems to deliver electronic contents and to support real-time communications. It is used as a tool to engage learners in collaborative, communicative, constructive and supportive activities. It is unique in ensuring ubiquity and mobility in learning without time, place and technical limitations. In the research literature, a number of successful m-learning systems are reviewed. Still there is lack of research about efficiency, effectiveness and usability of mobile learning systems. In this paper, we discuss the usability of a learning environment and propose a strategy how to implement a successful usable m-learning environment. MobileView is mobile application developed as a prototype for testing purposes as well as for developing a strategy for designing a usable m-learning environment.},
  eventtitle = {{{ITI}} 2008 - 30th {{International Conference}} on {{Information Technology Interfaces}}},
  file = {/home/valentin/Zotero/storage/27GGISWK/Fetaji1 et al. - 2008 - Usability testing and evaluation of a mobile softw.pdf;/home/valentin/Zotero/storage/2WMNEMDG/4588461.html},
  keywords = {Education,M-learning,Mobile communication,Mobile handsets,Prototypes,Testing,Usability,usability of mobile applications,User interfaces,wireless devices}
}

@article{finstad_UsabilityMetricUser_2010,
  title = {The {{Usability Metric}} for {{User Experience}}},
  author = {Finstad, K.},
  date = {2010-09},
  journaltitle = {Interacting with Computers},
  volume = {22},
  pages = {323--327},
  doi = {10.1016/j.intcom.2010.04.004},
  abstract = {The Usability Metric for User Experience (UMUX) is a four-item Likert scale used for the subjective assessment of an application's perceived usability. It is designed to provide results similar to those obtained with the 10-item System Usability Scale, and is organized around the ISO 9241\textendash 11 definition of usability. A pilot version was assembled from candidate items, which was then tested alongside the System Usability Scale during usability testing. It was shown that the two scales correlate well, are reliable, and both align on one underlying usability factor. In addition, the Usability Metric for User Experience is compact enough to serve as a usability module in a broader user experience metric.},
  eventtitle = {Interacting with {{Computers}}},
  file = {/home/valentin/Zotero/storage/VSUSHZN2/Finstad - 2010 - The Usability Metric for User Experience.pdf;/home/valentin/Zotero/storage/HGPD7GX6/8149786.html},
  keywords = {Metric,Scale,Usability,User experience},
  number = {5}
}

@article{fitts_SRCompatibilitySpatial_1953,
  title = {S-{{R}} Compatibility: Spatial Characteristics of Stimulus and Response Codes.},
  shorttitle = {S-{{R}} Compatibility},
  author = {Fitts, Paul M. and Seeger, Charles M.},
  date = {1953},
  journaltitle = {Journal of Experimental Psychology},
  shortjournal = {Journal of Experimental Psychology},
  volume = {46},
  pages = {199--210},
  doi = {10.1037/h0062827},
  file = {/home/valentin/Zotero/storage/BPQXDSHW/Fitts and Seeger - 2004 - S-R COMPATIBILITY  SPATIAL CHARACTERISTICS STIMUL.pdf},
  langid = {english},
  number = {3}
}

@online{garg_ISOIEC25010_,
  title = {{{ISO}}/{{IEC}} 25010:2011},
  shorttitle = {{{ISO}}/{{IEC}} 25010},
  author = {Garg, Reena and Dryden, Andrew and Chen, Yvonne},
  url = {https://www.iso.org/cms/render/live/en/sites/isoorg/contents/data/standard/03/57/35733.html},
  urldate = {2021-04-14},
  abstract = {Systems and software engineering \textemdash{} Systems and software Quality Requirements and Evaluation (SQuaRE) \textemdash{} System and software quality models},
  file = {/home/valentin/Zotero/storage/GXWBEWPK/35733.html},
  langid = {english},
  organization = {{ISO}}
}

@article{germanupa_UsabilityTestberichtTemplate_2014,
  title = {Usability-Testbericht, Template},
  author = {{German UPA}},
  date = {2014-08},
  pages = {34},
  url = {https://www.germanupa.de/sites/default/files/public/content/2018/2018-03-15/usability-testberichttemplate.doc},
  urldate = {2021-04-11},
  file = {/home/valentin/Zotero/storage/G3BTBKHF/usability-testberichttemplate.doc},
  langid = {german}
}

@online{gnomeproject_AcceptableResponseTimes_2014,
  title = {Acceptable {{Response Times}}},
  author = {{GNOME Project}},
  date = {2014},
  url = {https://developer.gnome.org/hig-book/unstable/feedback-response-times.html.en},
  urldate = {2021-05-05},
  file = {/home/valentin/Zotero/storage/M8BXMJJ7/feedback-response-times.html.html}
}

@online{gordon_PrinciplesVisualDesign_20,
  title = {5 {{Principles}} of {{Visual Design}} in {{UX}}},
  author = {Gordon, Kelly},
  date = {0020-03-01},
  url = {https://www.nngroup.com/articles/principles-visual-design/},
  urldate = {2021-04-21},
  abstract = {The principles of scale, visual hierarchy, balance, contrast, and Gestalt not only create beautiful designs, but also increase usability when applied correctly.},
  file = {/home/valentin/Zotero/storage/CL3VPUBE/principles-visual-design.html},
  langid = {english},
  organization = {{Nielsen Norman Group}}
}

@article{guna_UsersViewpointUsability_2017,
  title = {Users' Viewpoint of Usability and User Experience Testing Procedure - Gaining Methodological Insights in a Case of an Interactive {{HbbTV}} Application},
  author = {Guna, Joze and Stojmenova-duh, Emilija and Pogacnik, Matevz},
  date = {2017-08},
  journaltitle = {Multimedia Tools and Applications},
  volume = {76},
  pages = {16125--16143},
  url = {https://search-proquest-com.ezproxy.fh-salzburg.ac.at/scholarly-journals/users-viewpoint-usability-user-experience-testing/docview/1914450764/se-2?accountid=207885},
  abstract = {We present a novel meta-methodological approach for the user experience and usability methodology procedure evaluation, shown in an example of the user experience and usability study of an interactive HbbTV application. The idea behind this research is not only to evaluate and improve the TV-WEB service but also to gain insights how the participants perceived the whole Ux evaluation procedure itself. The research questions focused mainly on the time complexity (temporal demand) and the frustration level of the TV-WEB evaluation procedure. Additionally the appropriateness of the selected content used, interface and interaction design, and the service impressions and satisfaction/payment related questions was sought. A special questionnaire based on the NASA TLX standard test is presented. The concept has been successfully implemented in several live field trials in three countries (BiH, Serbia and Montenegro). In the user experience and usability study of the service itself more than 150 participants were involved, of those 35 took part in the meta-methodology study. The feedback was quantitatively evaluated on a 7-point Likert scale, with "1" indicating the best positive feedback, "4" neutral/undecided feedback and "7" the most negative feedback. The quantitative average summary results obtained in the three evaluation studies were 1.30 for both the BiH and Serbia test study cases and the score of 1.22 for the test study case in Montenegro. These results show that a great majority of the participants found the whole evaluation procedure time-wise and frustration-wise undemanding, with appropriate content, presentation style and overall attitude towards them. By using this approach it was possible to improve the user experience and usability methodology used, producing more reliable results and providing better user experience in the final version of the product as well as providing a pleasant experience during the testing of the product.},
  file = {/home/valentin/Zotero/storage/EM8MFESD/Guna et al. - 2017 - Users' viewpoint of usability and user experience .pdf},
  keywords = {34:Multimedia Information Systems (CI),Complexity,Computers–Software,Feedback,Frustration,Human-computer interaction,Meta-methodology,Methodology,Montenegro,Negative feedback,Positive feedback,SEE TV-WEB project,Serbia,Test procedures,TV and Internet,Usability,User centered design,User experience,User interfaces,User study},
  langid = {english},
  number = {15}
}

@article{haertel_TechniksteuerungDurchNormung_2021,
  title = {Techniksteuerung Durch {{Normung}} Am {{Beispiel}} Der {{Ergonomie}} von {{Speditionssoftware}}: {{Ergonomienorm}} Oder {{Ergononienorm}}?},
  shorttitle = {Techniksteuerung Durch {{Normung}} Am {{Beispiel}} Der {{Ergonomie}} von {{Speditionssoftware}}},
  author = {Haertel, Tobias},
  date = {2021-04-16},
  abstract = {The purpose of this study was to identify the impact of the software ergonomics standard ISO 9241-110:2006 (Ergonomics of human-system interaction: Dialogue principles). This standard was a result of norm giving activities in the 1980s and 1990s in a neo-corporatistic arrangement and aimed to protect VDU (Visual Display Unit) workers from harmful consequences of non-user-friendly software. Another intention of this study was to find out to which extend technology can be shaped in the field of application software for forwarders by the concerned actors. Finally, the pressure to change caused by the new technology ``software'' on the established institutions and social structures was examined.  Both qualitative and quantitative research methodology was utilised in this study. The qualitative research data consisted of two case studies based on in-depth interviews with forwarders and their computer administrators and of one in-depth interview with a representative of the ``Technologieberatungsstelle'', an organisation of the Federation of German Trade Unions consulting companies in technical affairs. The quantitative research data was gathered with the aid of a questionnaire. Employees in 15 forwarding agencies were surveyed and asked to rate the user-friendliness of the software they used. The results of the questionnaire revealed that the used application software in only 4 of 15 forwarding agencies complied with the ISO 9241-110:2006. The case studies and the in-depth interview with the representative of the ``Technologieberatungsstelle'' showed that employers, employees and trade unions had hardly any opportunities to shape software technology, although the ISO 9241-110:2006 had become part of the German body of laws. Finally it was found out that the pressure to change on the established institutions and social structures was low. The author recommends adjusting the governance mode of software ergonomics. It is recommended that software programmes according to the norm ISO 9241-110:2006 should become more visible through certification and get tax benefits. Thereby market mechanisms would be strengthened, and the capabilities of employers and employees to shape the technology socially compatible would be enhanced. In der Arbeit wird Wirksamkeit der Norm zur Softwareergonomie ISO 9241-110:2006 (Grunds\"atze der Dialoggestaltung) untersucht. Dieser Standard ist das Ergebnis normgebender Aktivit\"aten in den 1980er und 1990er Jahren und soll Bildschirmarbeiterinnen und Bildschirmarbeiter vor Gefahren sch\"utzen, die von nicht benutzerfreundlicher Software ausgehen k\"onnen. Am Beispiel von Speditionssoftware wird dabei auch der Frage nachgegangen, \"uber welche M\"oglichkeiten der Technikgestaltung die unterschiedlichen Akteure verf\"ugen und welcher Druck zur Ver\"anderung durch die neue Technik ,,Software`` auf Institutionen und soziale Strukturen ausge\"ubt wurde. Dazu wird ein Mix von quantitativen und qualitativen Methoden eingesetzt. Im qualitativen Teil werden 2 Fallstudien vorgenommen und Experteninterviews mit Speditionskaufleuten, EDV-Beauftragten, Speditionsinhabern und einem Gewerkschaftsvertreter gef\"uhrt. In der quantitativen Untersuchung werden die Mitarbeiterinnen und Mitarbeiter in 15 Speditionsbetrieben befragt, um die Einhaltung der ISO 9241:110 (2006) in den Unternehmen pr\"ufen zu k\"onnen. Als Ergebnis kann festgehalten werden, dass die Wirksamkeit der ISO 9241:110 (2006) sehr gering ist, dass die M\"oglichkeiten von Arbeitnehmerinnen und Arbeitnehmern zur Technikgestaltung auf der Mikro- und auf der Mesoebene gering sind und dass es im Zuge der Softwareergonomie zu keinen wesentlichen institutionellen Ver\"anderungen kam. Zum Schluss der Arbeit werden Gestaltungsvorschl\"age gemacht, die darauf abzielen, die Wirksamkeit der ISO 9241-110 (2006) zu erh\"ohen.},
  file = {/home/valentin/Zotero/storage/AR2Q2WEE/Haertel - 2021 - Techniksteuerung durch Normung am Beispiel der Erg.pdf}
}

@incollection{hart_DevelopmentNASATLXTask_1988,
  title = {Development of {{NASA}}-{{TLX}} ({{Task Load Index}}): {{Results}} of {{Empirical}} and {{Theoretical Research}}},
  shorttitle = {Development of {{NASA}}-{{TLX}} ({{Task Load Index}})},
  booktitle = {Advances in {{Psychology}}},
  author = {Hart, Sandra G. and Staveland, Lowell E.},
  editor = {Hancock, Peter A. and Meshkati, Najmedin},
  date = {1988-01-01},
  volume = {52},
  pages = {139--183},
  publisher = {{North-Holland}},
  doi = {10.1016/S0166-4115(08)62386-9},
  abstract = {The results of a multi-year research program to identify the factors associated with variations in subjective workload within and between different types of tasks are reviewed. Subjective evaluations of 10 workload-related factors were obtained from 16 different experiments. The experimental tasks included simple cognitive and manual control tasks, complex laboratory and supervisory control tasks, and aircraft simulation. Task-, behavior-, and subject-related correlates of subjective workload experiences varied as a function of difficulty manipulations within experiments, different sources of workload between experiments, and individual differences in workload definition. A multi-dimensional rating scale is proposed in which information about the magnitude and sources of six workload-related factors are combined to derive a sensitive and reliable estimate of workload.},
  file = {/home/valentin/Zotero/storage/LKHPVRDF/S0166411508623869.html},
  langid = {english},
  series = {Human {{Mental Workload}}}
}

@inproceedings{hart_NasataskLoadIndex_2006,
  title = {Nasa-Task Load Index ({{Nasa}}-{{TLX}}); 20 Years Later},
  author = {Hart, Sandra G. and Field, Moffett},
  date = {2006-10-01},
  volume = {50},
  doi = {10.1177/154193120605000909},
  abstract = {NASA-TLX is a multi-dimensional scale designed to obtain workload estimates from one or more operators while they are performing a task or immediately afterwards. The years of research that preceded subscale selection and the weighted averaging approach resulted in a tool that has proven to be reasonably easy to use and reliably sensitive to experimentally important manipulations over the past 20 years. Its use has spread far beyond its original application (aviation), focus (crew complement), and language (English). This survey of 550 studies in which NASA-TLX was used or reviewed was undertaken to provide a resource for a new generation of users. The goal was to summarize the environments in which it has been applied, the types of activities the raters performed, other variables that were measured that did (or did not) covary, methodological issues, and lessons learned},
  eventtitle = {Proceedings of the {{Human Factors}} and {{Ergonomics Society Annual Meeting}}},
  file = {/home/valentin/Zotero/storage/RW6ZPQKZ/Hart and Field - NASA-TASK LOAD INDEX (NASA-TLX)\; 20 YEARS LATER.pdf}
}

@incollection{HARTSON2012537,
  title = {Chapter 15 - Rigorous Empirical Evaluation: {{Running}} the Session},
  booktitle = {The {{UX}} Book},
  author = {Hartson, Rex and Pyla, Partha S.},
  editor = {Hartson, Rex and Pyla, Partha S.},
  date = {2012},
  pages = {537--554},
  publisher = {{Morgan Kaufmann}},
  location = {{Boston}},
  doi = {10.1016/B978-0-12-385241-0.00015-4}
}

@incollection{hass_PracticalGuideUsability_2019,
  title = {A {{Practical Guide}} to {{Usability Testing}}},
  booktitle = {Consumer {{Informatics}} and {{Digital Health}}: {{Solutions}} for {{Health}} and {{Health Care}}},
  author = {Hass, Christopher},
  editor = {Edmunds, Margo and Hass, Christopher and Holve, Erin},
  date = {2019},
  pages = {107--124},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-96906-0_6},
  abstract = {One of the most commonly practiced and most powerful tools in user experience research is usability testing, a fairly straightforward and highly effective methodology for identifying barriers to use and for illuminating opportunities for making products, services, and systems more effective, efficient, and satisfying to use. Usability tests can be conducted in a variety of environments with varying degrees of formality, collecting various types of qualitative and quantitative data, and with different types of teams working with the end-users. Usability testing focuses on the product or service, not on the end-user, and is an under-utilized tool in product and service development and implementation. This chapter will describe the steps involved in planning and executing a usability study, from choosing the audience and selecting the test setting to deciding what data to collect, and it provides a framework for evaluating study choices and trade-offs in assessing products, services, and systems to help to maximize the user's experience.},
  file = {/home/valentin/Zotero/storage/WQSKG73E/Hass - 2019 - A Practical Guide to Usability Testing.pdf},
  keywords = {Audience identification,Human-centered design,Informed consent,Moderator’s guide,Recruitment,Usability testing,User experience,User-centered design},
  langid = {english}
}

@inproceedings{heimgartner_HumanFactorsISO_2014,
  title = {Human {{Factors}} of {{ISO}} 9241-110 in the {{Intercultural Context}}},
  author = {Heimg\"artner, R\"udiger},
  date = {2014-01-01},
  abstract = {ISO 9241-110 describes seven dialog principles that should be applied in human computer interaction design. In this paper, some ideas are presented regarding the question whether these dialog principles are valid in general with the same strength or when used in different cultures around the world if there are differences in their applicability and subsequently how this question can be tackled. First, the influence of culture on the user's interaction with the system and on usability and usability engineering is elucidated. Second, cultural differences and methods to describe cultural differences such as cultural models are presented. Third, the analysis of the influence of culture on dialog principles is exemplified by the dialogue principle "suitability of the task". Finally, the results are discussed and challenges are identified. The ideas in this paper pave the way for deeper research in this area.}
}

@online{henty_UIResponseTimes_2017,
  title = {{{UI Response Times}}},
  author = {Henty, Steve},
  date = {2017-05-27T16:54:27},
  url = {https://medium.com/@slhenty/ui-response-times-acec744f3157},
  urldate = {2021-05-05},
  abstract = {This article is intended as a reference for defining and characterizing response times in a user interface. The classifications are derived\ldots},
  langid = {english},
  organization = {{Medium}}
}

@book{herczeg_SoftwareErgonomie_2018,
  title = {Software-Ergonomie},
  author = {Herczeg, Michael},
  date = {2018-03-05},
  publisher = {{De Gruyter Oldenbourg}},
  url = {https://www.degruyter.com/document/doi/10.1515/9783110446869/html},
  urldate = {2021-05-25},
  abstract = {Das Buch ist eine wissenschaftliche, aber leicht lesbare Einf\"uhrung in die Software-Ergonomie mit Vertiefungsthemen. Es diskutiert in systematischer Weise die wichtigsten Theorien, Modelle und Kriterien f\"ur gebrauchstaugliche Computeranwendungen. Dazu werden Grundlagen aus Arbeitswissenschaft, Psychologie, Design und Informatik interdisziplin\"ar verkn\"upft und umsetzungsorientiert dargestellt. Das Buch dient in vielen Hochschulen als Begleitbuch f\"ur Lehrmodule wie Software-Ergonomie oder Mensch-Computer-Interaktion in diversen Studieng\"angen. Die Inhalte orientieren sich an den Empfehlungen der Gesellschaft f\"ur Informatik. Der Band nimmt Bezug auf internationale Normen (insbesondere DIN EN ISO 9241) und Arbeitsschutzgesetze wie die Arbeitsst\"attenverordnung (ArbSt\"attV) und die Barrierefreie Informationstechnik-Verordnung (BITV 2.0). Dies macht das Buch auf f\"ur Praktiker zu einer wertvollen Grundlage f\"ur die Entwicklung benutzer- und aufgabengerechter interaktiver Computersysteme.},
  file = {/home/valentin/Zotero/storage/9KWXSDKQ/html.html},
  langid = {german}
}

@online{hickeys_AnimationsTransitionsWin32_,
  title = {Animations and {{Transitions}} - {{Win32}} Apps},
  author = {{hickeys}},
  url = {https://docs.microsoft.com/en-us/windows/win32/uxguide/vis-animations},
  urldate = {2021-05-17},
  abstract = {Strategic use of animations and transitions can make your program easier to understand, feel smoother, more natural, and of higher quality, and be more engaging.},
  file = {/home/valentin/Zotero/storage/8RYDXS2E/vis-animations.html},
  langid = {american}
}

@online{hickeys_UserInterfacePrinciples_,
  title = {User {{Interface Principles}} - {{Win32}} Apps},
  author = {{hickeys}},
  url = {https://docs.microsoft.com/en-us/windows/win32/appuistart/-user-interface-principles},
  urldate = {2021-05-17},
  abstract = {This topic discusses how to implement intuitive user interface and user experience design principles into a Windows applications.},
  file = {/home/valentin/Zotero/storage/UQBG6IUQ/-user-interface-principles.html},
  langid = {american}
}

@inproceedings{hornbaek_MetaanalysisCorrelationsUsability_2007,
  title = {Meta-Analysis of Correlations among Usability Measures},
  author = {Hornb\ae k, Kasper and {Kasper} and {Law} and L., Effie},
  date = {2007-01-01},
  doi = {10.1145/1240624.1240722},
  abstract = {Understanding the relation between usability measures seems crucial to deepen our conception of usability and to select the right measures for usability studies. We present a meta-analysis of correlations among usability measures calculated from the raw data of 73 studies. Correlations are generally low: effectiveness measures (e.g., errors) and efficiency measures (e.g., time) have a correlation of .247 {$\pm$} .059 (Pearson's product-moment correlation with 95\% confidence interval), efficiency and satisfaction (e.g., preference) one of .196 {$\pm$} .064, and effectiveness and satisfaction one of .164 {$\pm$} .062. Changes in task complexity do not influence these correlations, but use of more complex measures attenuates them. Standard questionnaires for measuring satisfaction appear more reliable than homegrown ones. Measures of users' perceptions of phenomena are generally not correlated with objective measures of the phenomena. Implications for how to measure usability are drawn and common models of usability are criticized. Author Keywords},
  eventtitle = {Conference on {{Human Factors}} in {{Computing Systems}} - {{Proceedings}}},
  file = {/home/valentin/Zotero/storage/IFIZPZZT/Hornbæk et al. - 2007 - Meta-analysis of correlations among usability meas.pdf}
}

@article{hoxmeier_SystemResponseTime_2000,
  title = {System {{Response Time}} and {{User Satisfaction}}: {{An Experimental Study}} of {{Browser}}-Based {{Applications}}},
  shorttitle = {System {{Response Time}} and {{User Satisfaction}}},
  author = {Hoxmeier, John and Dicesare, Chris and {Manager}},
  date = {2000-01-01},
  journaltitle = {Proceedings of the Association of Information Systems Americas Conference},
  shortjournal = {Proceedings of the Association of Information Systems Americas Conference},
  abstract = {With rapid advances in hardware speed and data communication bandwidth, one might not expect to have to deal with issues such as response time and system performance. But these issues remain a very real concern today. Lengthy system response times may cause lower satisfaction and poor productivity among users. Lowered user satisfaction may lead to discontinued use of an application, especially in discretionary applications such as those found on the Internet. The intent of this experimental research is to (1) substantiate that slow system response time leads to dissatisfaction; (2) assess the point at which users may become dissatisfied with system response time; (3) determine a threshold at which dissatisfaction may lead to discontinued use of the application, and (4) determine if experience influences response time tolerance. The results showed that indeed satisfaction does decrease as response time increases. However, instant response was not perceived as making the system easier to use or learn. It also showed that for discretionary applications, there appears to be a level of intolerance in the 12-second response range.}
}

@inproceedings{jones_EretentionInitialEvaluation_2003,
  title = {E-Retention: An Initial Evaluation of Student Withdrawals within a Virtual Learning Environment},
  shorttitle = {E-Retention},
  author = {Jones, Paul and Packham, Gary and Miller, Christopher and Davies, Ian and Jones, Amanda and Roberts, David},
  date = {2003-11-06},
  abstract = {The proliferation of e-learning programmes on offer within the UK raises critical issues that have yet to be fully addressed in terms of the nature of learning, effective pedagogy, learning expectations and student profile. The amalgamation and influence of these factors is also having an impact upon student retention. This paper examines student withdrawals associated with the BA Enterprise programme, part of the Objective 1 funded Enterprise College Wales (ECW) initiative designed by the University of Glamorgan, which aims to help improve the entrepreneurial capacity of Wales. Utilising content analysis of student feedback questionnaires at one of the University's delivery partners, 4 prime cases for student withdrawal were identified including factors such as technical problems, pressure of work and lack of time. The paper concludes by identifying strategies to manage these barriers to e-learning.},
  file = {/home/valentin/Zotero/storage/PFXLSBZV/JonesPackhamMillerandThomaselearninternational2004.doc}
}

@article{jones_InitialEvaluationStudent_2004,
  title = {An {{Initial Evaluation}} of {{Student Withdrawals}} within an E-{{Learning Environment}}: {{The Case}} of e-{{College Wales}}},
  shorttitle = {An {{Initial Evaluation}} of {{Student Withdrawals}} within an E-{{Learning Environment}}},
  author = {Jones, Paul and Packham, Gary and Miller, Christopher and Jones, Amanda},
  date = {2004-02},
  journaltitle = {Electronic Journal of e-Learning},
  volume = {2},
  pages = {113--120},
  publisher = {{Academic Conferences Limited}},
  url = {https://eric.ed.gov/?id=EJ1099218},
  urldate = {2021-05-28},
  abstract = {The proliferation of e-Learning programmes on offer within the UK raises critical issues that have yet to be fully addressed in terms of the nature of learning, effective pedagogy, learning expectations and student profile. The amalgamation and influence of these factors is also having an impact upon student retention. This paper examines student withdrawals associated with the online BA Enterprise programme initiative designed by the University of Glamorgan, which aims to help improve the entrepreneurial capacity of Wales. Utilising content analysis of student questionnaires at one of the University's delivery partners, eight prime cases for student withdrawal were identified including factors such as technical problems, pressure of work and lack of time. The paper concludes by identifying strategies to manage these barriers to e-Learning.},
  file = {/home/valentin/Zotero/storage/MZKA3QLJ/Jones et al. - 2004 - An Initial Evaluation of Student Withdrawals withi.pdf;/home/valentin/Zotero/storage/KKA3LFHR/eric.ed.gov.html},
  keywords = {Age Differences,College Students,Content Analysis,Dropout Research,Educational Environment,Electronic Learning,Entrepreneurship,Etiology,Foreign Countries,Gender Differences,Performance Factors,Qualitative Research,Questionnaires,Semi Structured Interviews,Statistical Analysis,Student Attrition,Student Employment,Student Experience,Withdrawal (Education)},
  langid = {english},
  number = {1}
}

@inproceedings{kerzazi_InquiryUsabilityTwo_2011,
  title = {Inquiry on Usability of Two Software Process Modeling Systems Using {{ISO}}/{{IEC}} 9241},
  booktitle = {2011 24th {{Canadian Conference}} on {{Electrical}} and {{Computer Engineering}}({{CCECE}})},
  author = {Kerzazi, N. and Lavall\'ee, M.},
  date = {2011-05},
  pages = {000773--000776},
  doi = {10.1109/CCECE.2011.6030560},
  abstract = {One of the most common limitations of software is poor usability. Usability refers to the effectiveness, efficiency, and satisfaction with which users achieve their particular goals in a particular context. This paper reports an experiment which evaluates the usability factors between two software process modeling systems, EPF-Composer and DSL4SPM. Based on the standard ISO/IEC 9241, a method has been designed for both subjective and objective evaluation of systems' usability. The method allows gathering the metrics that make up the usability scale. Our experiment, involving 14 teams, provides insights on how to enhance the design of software products. The results shows that a combination of objective and subjective evaluations provide a more complete view of usability.},
  eventtitle = {2011 24th {{Canadian Conference}} on {{Electrical}} and {{Computer Engineering}}({{CCECE}})},
  file = {/home/valentin/Zotero/storage/XLD2HZFC/Kerzazi und Lavallée - 2011 - Inquiry on usability of two software process model.pdf;/home/valentin/Zotero/storage/4BGP2QFA/6030560.html},
  keywords = {Context,EPF-Composer,IEC standards,ISO standards,ISO/IEC 9241,ISO/IEC 9241 standard,Measurement,Reliability,software process improvement,Software Process Modeling,software process modeling systems,software products,software reusability,software usability,SPEM,Usability}
}

@book{lakoff_MetaphorsWeLive_2003,
  title = {Metaphors We Live By},
  author = {Lakoff, George and Johnson, Mark},
  date = {2003-04-15},
  edition = {1st Edition},
  publisher = {{University of Chicago Press}},
  location = {{Chicago}},
  langid = {Englisch}
}

@article{lindgaard_JUDGINGWEBPAGE_2021,
  title = {{{JUDGING WEB PAGE VISUAL APPEAL}}: {{DO EAST AND WEST REALLY DIFFER}}?},
  shorttitle = {{{JUDGING WEB PAGE VISUAL APPEAL}}},
  author = {Lindgaard, Gitte and Litwinska, Justyna and Dudek, Cathy},
  date = {2021-05-17},
  abstract = {Two studies exploring potential cultural difference in taste are presented in which visual appeal is rated for a set of North American and Taiwanese/Chinese web pages each seen for either 500-or 50 milliseconds. Study 1 confirmed the universality of the mere exposure effect, reflecting a physiologically-based more or less intense feeling of pleasure. Chinese/Taiwanese participants rated visual appeal significantly more highly than Canadians when judging web pages representing their native culture, but no differences emerged in visual appeal ratings of North American web pages. The results are ambivalent with respect to the issue of localization vis \`a vis globalization of web pages. The studies identify a preliminary set of attributes of visually appealing web pages.},
  file = {/home/valentin/Zotero/storage/YGFPJ3E3/Lindgaard et al. - 2021 - JUDGING WEB PAGE VISUAL APPEAL DO EAST AND WEST R.pdf}
}

@online{loranger_ChecklistPlanningUsability_2016,
  title = {Checklist for {{Planning Usability Studies}}},
  author = {Loranger, Hoa},
  date = {2016-04-17},
  url = {https://www.nngroup.com/articles/usability-test-checklist/},
  urldate = {2021-04-16},
  abstract = {Planning a user test? Follow these 9 steps to make sure you are prepared.},
  file = {/home/valentin/Zotero/storage/VFC8JB8P/usability-test-checklist.html},
  langid = {english},
  organization = {{Nielsen Norman Group}}
}

@book{lupton_GraphicDesignNew_2015,
  title = {Graphic Design: The New Basics},
  shorttitle = {Graphic Design},
  author = {Lupton, Ellen and Phillips, Jennifer C.},
  date = {2015},
  edition = {Second edition, revised and expanded},
  publisher = {{Princeton Architectural Press ; Maryland Institute College of Art}},
  location = {{New York : Baltimore}},
  file = {/home/valentin/Zotero/storage/GGPGINUH/Lupton and Phillips - 2015 - Graphic design the new basics.pdf},
  keywords = {Graphic arts}
}

@article{miller_ResponseTimeMancomputer_1968,
  title = {Response Time in Man-Computer Conversational Transactions},
  author = {Miller, Robert},
  date = {1968-01-01},
  journaltitle = {AFIPS Spring Joint Computer Conference},
  shortjournal = {AFIPS Spring Joint Computer Conference},
  volume = {33},
  pages = {267--277},
  doi = {10.1145/1476589.1476628},
  abstract = {The literature concerning man-computer transactions abounds in controversy about the limits of "system response time" to a user's command or inquiry at a terminal. Two major semantic issues prohibit resolving this controversy. One issue centers around the question of "Response time to what?" The implication is that different human purposes and actions will have different acceptable or useful response times.}
}

@book{newell_UnifiedTheoriesCognition_1994,
  title = {Unified Theories of Cognition},
  author = {Newell, Allen},
  date = {1994},
  edition = {1. Harvard Univ. Press paperback ed},
  publisher = {{Harvard Univ. Press}},
  location = {{Cambridge, Mass.}},
  annotation = {OCLC: 247363531},
  file = {/home/valentin/Zotero/storage/86YNDHJS/Unified Theories of Cognition (William James Lectures) by Allen Newell (z-lib.org).pdf;/home/valentin/Zotero/storage/CJNKHBNF/Newell - 1994 - Unified theories of cognition.pdf},
  langid = {english},
  number = {1987},
  series = {The {{William James}} Lectures}
}

@online{nielsen_10UsabilityHeuristics_2020,
  title = {10 {{Usability Heuristics}} for {{User Interface Design}}},
  author = {Nielsen, Jakob},
  date = {2020-11-15},
  url = {https://www.nngroup.com/articles/ten-usability-heuristics/},
  urldate = {2021-04-14},
  abstract = {Jakob Nielsen's 10 general principles for interaction design. They are called "heuristics" because they are broad rules of thumb and not specific usability guidelines.},
  file = {/home/valentin/Zotero/storage/925FU8DR/ten-usability-heuristics.html},
  langid = {english},
  organization = {{10 Usability Heuristics for User Interface Design}}
}

@online{nielsen_ConfirmationDialogsCan_18,
  title = {Confirmation {{Dialogs Can Prevent User Errors}} ({{If Not Overused}})},
  author = {Nielsen, Jakob},
  date = {0018-02-18},
  url = {https://www.nngroup.com/articles/confirmation-dialog/},
  urldate = {2021-04-21},
  abstract = {8 UX guidelines to avoid many serious user errors reduce the risk that people automatically agree to a warning without realizing the consequences.},
  file = {/home/valentin/Zotero/storage/94WI3A2Q/confirmation-dialog.html},
  langid = {english},
  organization = {{Nielsen Norman Group}}
}

@book{nielsen_EyetrackingWebUsability_2010,
  title = {Eyetracking Web Usability},
  author = {Nielsen, Jakob and Pernice, Kara},
  date = {2010},
  publisher = {{New Riders}},
  location = {{Berkeley, CA}},
  abstract = {Based on one of the largest studies of eyetracking usability in existence used rigorous methodology and eyetracking technology to analyze 1.5 million instances where users look at Web sites. Their findings will help designers, software developers, writers, editors, product managers, and advertisers understand how the human eyes interact with Web sites and what will significantly improve user experience.-- Publisher info},
  annotation = {OCLC: ocn495471898},
  file = {/home/valentin/Zotero/storage/6IWHDJ2B/Nielsen und Pernice - 2010 - Eyetracking web usability.pdf},
  keywords = {Design,Evaluation,Testing,User interfaces (Computer systems),Web sites}
}

@online{nielsen_HeuristicEvaluationHowTo_1994,
  title = {Heuristic {{Evaluation}}: {{How}}-{{To}}: {{Article}} by {{Jakob Nielsen}}},
  shorttitle = {Heuristic {{Evaluation}}},
  author = {Nielsen, Jakob},
  date = {1994-11-01},
  url = {https://www.nngroup.com/articles/how-to-conduct-a-heuristic-evaluation/},
  urldate = {2021-04-14},
  abstract = {Heuristic evaluation involves having a small set of evaluators examine the interface and judge its compliance with recognized usability principles (the "heuristics").},
  file = {/home/valentin/Zotero/storage/GYNGFM5X/how-to-conduct-a-heuristic-evaluation.html},
  langid = {english},
  organization = {{How to Conduct a Heuristic Evaluation}}
}

@inproceedings{nielsen_MathematicalModelFinding_1993,
  title = {A Mathematical Model of the Finding of Usability Problems},
  booktitle = {Proceedings of the {{SIGCHI}} Conference on {{Human}} Factors in Computing Systems  - {{CHI}} '93},
  author = {Nielsen, Jakob and Landauer, Thomas K.},
  date = {1993},
  pages = {206--213},
  publisher = {{ACM Press}},
  location = {{Amsterdam, The Netherlands}},
  doi = {10.1145/169059.169166},
  abstract = {Why you only need to test with 5 users},
  eventtitle = {The {{SIGCHI}} Conference},
  file = {/home/valentin/Zotero/storage/GITIX2ND/Nielsen und Landauer - 1993 - A mathematical model of the finding of usability p.pdf},
  langid = {english}
}

@book{nielsen_MobileUsability_2013,
  title = {Mobile Usability},
  author = {Nielsen, Jakob and Budiu, Raluca},
  date = {2013},
  publisher = {{New Riders}},
  location = {{Berkeley, CA}},
  annotation = {OCLC: ocn796754695},
  keywords = {Application software,Development,Mobile computing,User interfaces (Computer systems),Web site development}
}

@online{nielsen_Powers10Time_2009,
  title = {Powers of 10: {{Time Scales}} in {{User Experience}}},
  shorttitle = {Powers of 10},
  author = {Nielsen, Jakob},
  date = {2009-10-04},
  url = {https://www.nngroup.com/articles/powers-of-10-time-scales-in-ux/},
  urldate = {2021-05-17},
  abstract = {From 0.1 seconds to 10 years or more, user interface design has many different timeframes, and each has its own particular usability issues.},
  file = {/home/valentin/Zotero/storage/I746838K/powers-of-10-time-scales-in-ux.html},
  langid = {english},
  organization = {{Nielsen Norman Group}}
}

@book{nielsen_UsabilityEngineering_1993,
  title = {Usability Engineering},
  author = {Nielsen, Jakob},
  date = {1993},
  publisher = {{Academic Press}},
  location = {{Boston}},
  file = {/home/valentin/Zotero/storage/KU5PHCUB/Nielsen - 1993 - Usability Engineering.pdf},
  keywords = {Computer software,Development,User interfaces (Computer systems)}
}

@book{norman_DesignEverydayThings_2013,
  title = {The Design of Everyday Things: Revised and Expanded Edition},
  shorttitle = {The Design of Everyday Things},
  author = {Norman, Don},
  date = {2013-11-05},
  edition = {Revised Edition},
  publisher = {{Basic Books}},
  location = {{New York, New York}},
  langid = {Englisch}
}

@article{officeofinformationtechnology_GUIProgrammingStandards_2010,
  title = {{{GUI Programming Standards}} and {{Conventions}}},
  author = {{Office of Information Technology}},
  date = {2010},
  file = {/home/valentin/Zotero/storage/8B4BJX2A/2010 - GUI Programming Standards and Conventions.pdf}
}

@inproceedings{paz_HeuristicEvaluationComplement_2015,
  title = {Heuristic {{Evaluation}} as a {{Complement}} to {{Usability Testing}}: {{A Case Study}} in {{Web Domain}}},
  shorttitle = {Heuristic {{Evaluation}} as a {{Complement}} to {{Usability Testing}}},
  booktitle = {2015 12th {{International Conference}} on {{Information Technology}} - {{New Generations}}},
  author = {Paz, F. and Paz, F. A. and Villanueva, D. and Pow-Sang, J. A.},
  date = {2015-04},
  pages = {546--551},
  doi = {10.1109/ITNG.2015.92},
  abstract = {Usability testing is one of the most used methods to define the level of usability of a software product. However, there is always uncertainty to determine the best method that complements user testing in a depth usability assessment. Nowadays, the concern of many software developers is to identify an appropriate methodology, whose evaluation methods could be capable of measuring all usability aspects of a user interface. For this reason, we conducted a heuristic evaluation as a preliminary step to the implementation of a usability test, in order to determine in which extent these methods complement each other, and establish the gaps which are covered by each of them. The heuristic evaluation was performed by five specialists in the field of Human-Computer Interaction, who identified a total of fifty-nine usability problems in a transactional web site. Subsequently, a usability test was conducted with the participation of eight postgraduate students of a master's program in Informatics Engineering. The results show that most of the usability problems which were detected during the usability testing, had already been identified by the heuristic evaluation. Nevertheless, there were significant differences in the importance that was given to each problem. Usability experts emphasized in aspects that were not relevant to end users.},
  eventtitle = {2015 12th {{International Conference}} on {{Information Technology}} - {{New Generations}}},
  file = {/home/valentin/Zotero/storage/CIMFKMEN/Paz et al. - 2015 - Heuristic Evaluation as a Complement to Usability .pdf;/home/valentin/Zotero/storage/I26A2IJG/7113530.html},
  keywords = {Graphical user interfaces,heuristic evaluation,human computer-interaction,Informatics,Standards,Testing,transactional web applications,Usability,usability study,usability testing}
}

@article{riedemann_UsabilityTestberichtBeispiel_2014,
  title = {Usability-Testbericht, Beispiel},
  author = {Riedemann, Catharina and Daske, Lisa and Molich, Rolf},
  date = {2014-08},
  pages = {34},
  url = {https://www.germanupa.de/sites/default/files/public/content/2018/2018-03-15/usability-testberichtbeispiel.pdf},
  urldate = {2021-04-11},
  file = {/home/valentin/Zotero/storage/STUGB37H/Riedemann et al. - 2014 - Herausgeber German UPA e.V., Arbeitskreis Qualitä.pdf},
  langid = {german}
}

@online{rohrer_WhenUseWhich_2014,
  title = {When to {{Use Which User}}-{{Experience Research Methods}}},
  author = {Rohrer, Christian},
  date = {2014-10-12},
  url = {https://www.nngroup.com/articles/which-ux-research-methods/},
  urldate = {2021-04-14},
  abstract = {20 user-research methods: where they fit in the design process, whether they are attitudinal or behavioral, qualitative or quantitative, and their context of use.},
  file = {/home/valentin/Zotero/storage/CFBR9QA7/which-ux-research-methods.html},
  langid = {english},
  organization = {{Nielsen Norman Group}}
}

@online{scholl_ImplementationUserExperienceBasedEvaluation_,
  title = {An {{Implementation}} of {{User}}-{{Experience}}-{{Based Evaluation}} to {{Achieve Transparency}} in the {{Usage}} and {{Design}} of {{Information Artifacts}}},
  author = {Scholl, Margot},
  url = {http://ieeexplore.ieee.org/document/7069662/},
  urldate = {2021-04-12},
  abstract = {User experience (UX) is a concept that covers the total effect of all the elements of an IT system on the user. An information artifact (IA) can contain any kind of information. In order to increase transparency in the usage and design of online and offline IA, the TEDS framework was implemented in Moodle as an electronic evaluation activity (TEDS*MOODLE) to evaluate the Moodle course rooms. Moreover, for the sake of enhancing UX transparency, it was extensively tested with students from the UAS Wildau's administration and law department from September 2013 to January 2014 and used to evaluate two online training courses and other kinds of IA. The results demonstrate the functionality and limitations of the application for different kinds of IA. Individual UX can be used to improve the quality and design of IA. The application itself is based on DIN EN ISO 9241-110 and confirmed the recommendations of this standard.},
  file = {/home/valentin/Zotero/storage/JUQCE86I/Scholl - An Implementation of User-Experience-Based Evaluat.pdf;/home/valentin/Zotero/storage/NPDDVYS6/7069662.html},
  langid = {american}
}

@book{seow_DesigningEngineeringTime_2008,
  title = {Designing and {{Engineering Time}}: {{The Psychology}} of {{Time Perception}} in {{Software}}},
  shorttitle = {Designing and {{Engineering Time}}},
  author = {Seow, Steven C.},
  date = {2008},
  edition = {1},
  publisher = {{Addison-Wesley Professional}},
  file = {/home/valentin/Zotero/storage/QKH7EPFA/Seow - 2008 - Designing and Engineering Time The Psychology of .pdf}
}

@inproceedings{spool_TestingWebSites_2001,
  title = {Testing Web Sites: Five Users Is Nowhere near Enough},
  shorttitle = {Testing Web Sites},
  author = {Spool, Jared and {Jared} and {Schroeder} and {Will}},
  date = {2001-03-31},
  doi = {10.1145/634067.634236},
  abstract = {We observed the same task executed by 49 users on four production web sites. We tracked the rates of discovery of new usability problems on each site and, using that data, estimated the total number of usability problems on each site and the number of tests we would need to discover every problem. Our findings differ sharply from rules-of-thumb derived from earlier work by Virzi[1] and Nielsen[2,3] commonly viewed as "industry standards." We found that the four sites we studied would need considerably more than five users to find 85},
  file = {/home/valentin/Zotero/storage/77N2HG2A/Spool et al. - 2001 - Testing web sites five users is nowhere near enou.pdf}
}

@inproceedings{tokkonen_HowUserExperience_2013,
  title = {How User Experience Is Understood?},
  booktitle = {2013 {{Science}} and {{Information Conference}}},
  author = {Tokkonen, Helena and Saariluoma, Pertti},
  date = {2013-10},
  pages = {791--795},
  abstract = {There have been many attempts to understand the phenomenon of user experience (UX), but a widely accepted theory is still missing. In this paper we present the results of our investigations on the practical and multidimensional side of user experience. We have studied how professional designers and novices with different backgrounds understand user experience. According to our findings there are three important user experience components: user, product and company. User is perceived to be in the center of user experience among professionals. The importance of user's feelings as part of a holistic user experience is emphasized. For novice designers experiences concerning the use of a product are more important than user's feelings. Technical solutions provided by a company, cultural matters and customer feedback are factors to be considered when targeting a holistic user experience.},
  eventtitle = {2013 {{Science}} and {{Information Conference}}},
  file = {/home/valentin/Zotero/storage/9FP2KZLN/Tokkonen and Saariluoma - 2013 - How user experience is understood.pdf;/home/valentin/Zotero/storage/SHXUYEHV/6661831.html},
  keywords = {Cognitive science,Companies,Context,Cultural differences,design,Educational institutions,Presses,Usability,user experience,user experience components}
}

@book{tullis_MeasuringUserExperience_2013,
  title = {Measuring the User Experience: Collecting, Analyzing, and Presenting Usability Metrics},
  shorttitle = {Measuring the User Experience},
  author = {Tullis, Tom and Albert, Bill},
  date = {2013},
  edition = {Second edition},
  publisher = {{Elsevier/Morgan Kaufmann}},
  location = {{Amsterdam ; Boston}},
  file = {/home/valentin/Zotero/storage/Z8H59FFU/Tullis and Albert - 2013 - Measuring the user experience collecting, analyzi.pdf},
  keywords = {Evaluation,Measurement,Technology assessment,User interfaces (Computer systems)}
}

@incollection{tullis_NumberParticipants_2013,
  title = {Number of Participants},
  booktitle = {Measuring the User Experience: Collecting, Analyzing, and Presenting Usability Metrics},
  author = {Tullis, Tom and Albert, Bill},
  date = {2013},
  edition = {Second edition},
  pages = {115--118},
  publisher = {{Elsevier/Morgan Kaufmann}},
  location = {{Amsterdam ; Boston}},
  keywords = {Evaluation,Measurement,Technology assessment,User interfaces (Computer systems)}
}

@article{virzi_RefiningTestPhase_1992a,
  title = {Refining the {{Test Phase}} of {{Usability Evaluation}}: {{How Many Subjects Is Enough}}?},
  shorttitle = {Refining the {{Test Phase}} of {{Usability Evaluation}}},
  author = {Virzi, Robert A.},
  date = {1992-08-01},
  journaltitle = {Human Factors},
  shortjournal = {Hum Factors},
  volume = {34},
  pages = {457--468},
  publisher = {{SAGE Publications Inc}},
  doi = {10.1177/001872089203400407},
  abstract = {Attention has been given to making user interface design and testing less costly so that it might be more easily incorporated into the product development life cycle. Three experiments are reported in this paper that relate the proportion of usability problems identified in an evaluation to the number of subjects participating in that study. The basic findings are that (a) 80\% of the usability problems are detected with four or five subjects, (b) additional subjects are less and less likely to reveal new information, and (c) the most severe usability problems are likely to have been detected in the first few subjects. Ramifications for the practice of human factors are discussed as they relate to the type of usability test cycle employed and the goals of the usability test.},
  langid = {english},
  number = {4}
}

@online{wagner_WasIstUsability_2017,
  title = {Was ist Usability? - Eine ausf\"uhrliche Erkl\"arung},
  shorttitle = {Was ist Usability?},
  author = {Wagner, Dennis},
  date = {2017-12-10T18:35:35+00:00},
  url = {https://uxfox.de/was-ist-usability/},
  urldate = {2021-05-04},
  abstract = {Was ist Usability? Usability beschreibt die Gebrauchstauglichkeit eines Systems. Es gibt 7 Grundpfeiler auf die sich Usability st\"utzt. Welche das sind erfahrt ihr in diesem Artikel.},
  file = {/home/valentin/Zotero/storage/XXU97UMZ/was-ist-usability.html},
  langid = {german},
  organization = {{UX Fox}}
}

@online{whitenton_MinimizeCognitiveLoad_13,
  title = {Minimize {{Cognitive Load}} to {{Maximize Usability}}},
  author = {Whitenton, Kathryn},
  date = {0013-12-22},
  url = {https://www.nngroup.com/articles/minimize-cognitive-load/},
  urldate = {2021-04-21},
  abstract = {The total cognitive load, or amount of mental processing power needed to use your site, affects how easily users find content and complete tasks.},
  file = {/home/valentin/Zotero/storage/2R49UXN5/minimize-cognitive-load.html},
  langid = {english},
  organization = {{Nielsen Norman Group}}
}

@inproceedings{wibowo_HeuristicEvaluationUser_2017,
  title = {Heuristic Evaluation and User Testing with {{ISO}} 9126 in Evaluating of Decision Support System for Recommendation of Outstanding Marketing Officer},
  booktitle = {2017 {{International Conference}} on {{Sustainable Information Engineering}} and {{Technology}} ({{SIET}})},
  author = {Wibowo, R. M. and Erna, P. A. and Hidayah, I.},
  date = {2017-11},
  pages = {454--458},
  doi = {10.1109/SIET.2017.8304181},
  abstract = {Multi-Criteria Decision Making in implementation of the Decision Support System (DSS) at BRI Katamso Yogyakarta helps decision makers in providing alternative decisions to choose the outstanding marketing office (MO) with DSS process. After implementation DSS in BRI Katamso, the next step is to evaluate the DSS. The purpose of this paper is to evaluate the DSS by using heuristic evaluation and ISO 9126. Evaluation is needed to test whether the system as expected. An evaluation of the designed system is expected to answer if any problems and improve goal attainment. ISO 9126 works to determine the level of effectiveness, efficiency, satisfaction. Heuristic Evaluation have function to evaluate the User Interface of DSS. Based on the ISO and heuristic evaluation, the general design of the interface and some of the factors effectiveness, efficiency, satisfaction vielded the average value of 3.75 (on a scale of 5).},
  eventtitle = {2017 {{International Conference}} on {{Sustainable Information Engineering}} and {{Technology}} ({{SIET}})},
  file = {/home/valentin/Zotero/storage/HWC3EC7C/Wibowo et al. - 2017 - Heuristic evaluation and user testing with ISO 912.pdf;/home/valentin/Zotero/storage/AUIKHDLS/8304181.html},
  keywords = {BRI Katamso,Decision support systems,DSS,Heuristic Evaluation,ISO 9126,ISO Standards,Marketing Officer,Navigation,Software,Testing,User interfaces}
}


